#
# COPYRIGHT Ericsson 2021
#
#
#
# The copyright to the computer program(s) herein is the property of
#
# Ericsson Inc. The programs may be used and/or copied only with written
#
# permission from Ericsson Inc. or in accordance with the terms and
#
# conditions stipulated in the agreement/contract under which the
#
# program(s) have been supplied.
#

modelVersion: 2.0

description: "Ericsson Java Spring Boot This microservice will fetch PM Counter Files and transfer to BDR  files"

# See image catalog: https://confluence.lmera.ericsson.se/display/ACD/ADP+CICD+Docker+Image+Catalog
docker-images:
  - adp-asciidoc-builder: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-asciidocbuilder:${env.ASCII_DOC_BUILDER_TAG}
  - adp-doc-builder: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-docbuilder:${env.DOC_BUILDER_TAG}
  - adp-helm-dr-check: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/adp-helm-dr-checker:${env.HELM_DR_CHECK_TAG}
  - adp-helm-kubectl: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-py3kubehelmbuilder:${env.HELM_KUBECTL_TAG}
  - adp-image-dr-check: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/adp-image-dr-check:${env.IMAGE_DR_CHECK_TAG}
  - adp-maven-builder: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-java17mvnbuilder:${env.MVN_BUILDER_TAG}
  - adp-release-auto: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/bob-adp-release-auto:${env.RELEASE_AUTO_TAG}
  - elib-make-utilities: ${elib-make-subpath}-oss-drop/eric-elib/elib_makeutilities:${env.ELIB_MAKE_UTILITIES_TAG}
  - grype-scan: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/va-image-scanning-grype:${env.ANCHORE_TAG}
  - trivy-inline-scan: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/trivy-inline-scan:${env.TRIVY_TAG}
  - va-scan-kubesec: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/va-scan-kubesec:${env.KUBESEC_TAG}
  - va-scan-kubeaudit: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/va-scan-kubeaudit:${env.KUBEAUDIT_TAG}
  - va-scan-kubehunter: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/va-scan-kubehunter:${env.KUBEHUNTER_TAG}
  - hadolint-scan: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/hadolint-scan:${env.HADOLINT_TAG}

import:
  common: ../common-properties.yaml

# List of constants
properties:
  - elib-make-subpath: armdocker.rnd.ericsson.se/proj-eric
  - project-subpath: proj-eric-oss
  - image-registry-path: armdocker.rnd.ericsson.se/proj-eric-oss
  - image-secret: armdocker
  - image-dev-repopath: ${image-registry-path}-dev
  - image-ci-repopath: ${image-registry-path}-ci-internal
  - image-drop-repopath: ${image-registry-path}-drop
  - image-ci-full-name: ${image-ci-repopath}/${common.docker-image-name}
  - image-full-name: ${image-drop-repopath}/${common.docker-image-name}

  # Helm Chart name must follow the pattern: eric-[a-z0-9]{1,5}-[a-z0-9-]{1,30}
  - helm-chart-repo-server-path: ${common.arm-repository-url}/proj-eric-oss
  - helm-chart-dev-repopath: ${helm-chart-repo-server-path}-dev-helm
  - helm-chart-ci-repopath: ${helm-chart-repo-server-path}-ci-internal-helm
  - helm-chart-drop-repo: ${helm-chart-repo-server-path}-drop-helm
  - helm-chart-release-repo: ${helm-chart-repo-server-path}-released-helm-local
  - arm-doc-dev: ${helm-chart-repo-server-path}-dev-generic-local/eric-oss-sftp-filetrans
  - arm-doc-released: ${helm-chart-repo-server-path}-released-generic-local/eric-oss-sftp-filetrans

  # Generic repository for publishing artifacts such as documentation
  - generic-drop-repo: ${helm-chart-repo-server-path}-drop-generic

  # Functional ID for your Team or CI group to push to Gerrit repo
  - git-user: ossadmin
  - git-repo-path: OSS/com.ericsson.oss.adc/eric-oss-pmcounter-filetrans
  - git-repo-url: https://gerrit-gamma.gic.ericsson.se/${git-repo-path}.git
  - git-repo: https://gerrit-gamma.gic.ericsson.se/#/admin/projects/${git-repo-path}

  - enabled-helm-design-rules: "-DhelmDesignRule.config.drHc011=enable -DhelmDesignRule.config.DR-D1120-045-AD=enable -DhelmDesignRule.config.DR-D1123-113=exempt"

  # FOSSA
  - fossa-server-endpoint: https://scasfossa.internal.ericsson.com
  - fossa-ci-repopath: ${helm-chart-repo-server-path}-dev-generic-local/fossa
  - fossa-service-name: eric-oss-sftp-filetrans
  - fossa-scan-report-artifact-path: ${fossa-ci-repopath}/${fossa-service-name}
  - fossa-scan-artifact-file-name: ${fossa-service-name}-${var.commithash}.tgz
  - fossa-project-name: ${common.helm-chart-name}
  - fossa-report-name: fossa-report.json
  - dependency-file-name: plms/dependencies.yaml
  - fossa-team-name: ${common.fossa-team-name}
  - docker-params: "--workdir ${env.PWD}"

  # VA IMAGES
  - image-to-scan: ${image-ci-full-name}:${var.version}
  - anchore-grype-image: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/va-image-scanning-grype:latest
  - trivy-image: armdocker.rnd.ericsson.se/proj-adp-cicd-drop/trivy-inline-scan:latest

  # Characteristic test report location
  - characteristic-test-report: ${env.PWD}/doc/Characteristic_Test_Report/characteristic_test_report.md
  - test-report: ${env.PWD}/doc/Test_Report/test_report.md

# import environment variables (For example: Jenkins parameters)
env:
  - HOME
  - MAVEN_CLI_OPTS (default=-Duser.home=${env.HOME} -B)
  - MAVEN_OPTS (default=-Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn)
  - PWD
  - RELEASE (default=false)
  - DOCKER_VOLUME_MAPPING_PASSWD (default=--volume ${env.HOME}/mypasswd:/etc/passwd:ro)
  - PROJ_MVN (default=/proj/mvn)

  # Kubernetes
  - COLLECT_LOGS_SCRIPT_LOCATION (default="https://arm.sero.gic.ericsson.se/artifactory/proj-ADP_GS_Support_FTP-generic-local/collect_ADP_logs")
  - COLLECT_LOGS_SCRIPT_FILE_NAME (default="collect_ADP_logs.sh")
  - COLLECT_LOGS_SINCE_RELATIVE_TIME (default="2h")
  - COLLECT_LOGS_DIR (default=./k8s-logs)
  - ENABLE_HELM_V3 (default=true)
  - HELM_INSTALL_TIMEOUT (default=5m0s)
  - HELM_RELEASE (default=${common.helm-chart-name}-release)
  - HELM_TEST_TIMEOUT (default=5m0s)
  - K8S_NAMESPACE (default=${common.helm-chart-name}-${var.commithash})
  - KUBECONFIG (default=${env.HOME}/.kube/config)
  - DOCKERCONFIG (default=$HOME/.docker/config.json)
  - BUILD_DIR (default=./build)
  - KAAS_INFO_FILE (default=${env.BUILD_DIR}/kaas-info.log)

  # Credentials
  - ERIDOC_USERNAME
  - ERIDOC_PASSWORD
  - GERRIT_USERNAME
  - GERRIT_PASSWORD
  - GERRIT_CHANGE_NUMBER (default=$GERRIT_CHANGE_NUMBER)
  - GERRIT_CHANGE_URL
  - JIRA_USERNAME
  - JIRA_PASSWORD
  - SELI_ARTIFACTORY_REPO_USER
  - SELI_ARTIFACTORY_REPO_PASS
  - SERO_ARTIFACTORY_REPO_USER
  - SERO_ARTIFACTORY_REPO_PASS
  - MARKETPLACE_TOKEN

  # Default docker image tags
  - ASCII_DOC_BUILDER_TAG (default=latest)
  - DOC_BUILDER_TAG (default=2.3.0-latest)
  - ELIB_MAKE_UTILITIES_TAG (default=latest)
  - HELM_DR_CHECK_TAG (default=latest)
  - HELM_KUBECTL_TAG (default=latest)
  - IMAGE_DR_CHECK_TAG (default=latest)
  - MVN_BUILDER_TAG (default=latest)
  - RELEASE_AUTO_TAG (default=latest)

  # VA Tools docker image tags
  - ANCHORE_TAG (default=latest)
  - TRIVY_TAG (default=latest)
  - KUBESEC_TAG (default=latest)
  - KUBEAUDIT_TAG (default=latest)
  - KUBEHUNTER_TAG (default=latest)
  - HADOLINT_TAG (default=latest)

  # SonarQube
  - SONAR_AUTH_TOKEN
  - SONAR_HOST_URL
  - SONAR_BRANCH (default="master")

  # SCAS
  - SCAS_TOKEN

  # FOSSA
  - FOSSA_ARTIFACT_HASH
  - FOSSA_API_KEY

  # Mimer
  - MUNIN_TOKEN

  # X-RAY
  - XRAY_USER
  - XRAY_APIKEY

  # VHUB
  - VHUB_API_TOKEN

# Variables, set by below tasks
var:
  - commithash
  - commithash-full
  - commit-author
  - commit-email
  - docker-config-basepath
  - start-time-seconds
  - end-time-seconds
  - elapsed-time
  - image-registry
  - helm-chart-repo-internal
  - image-full-name-internal
  - image-repopath-internal
  - image-repopath-drop
  - pom-version
  - revision
  - rstate
  - version
  - version-prefix: VERSION_PREFIX
  - image-dr-vm-args
  - kaas-version
  - kaas-current-context
  - resultcode_hadolint_check
  - save-namespace
  - service-pods
  - zap-epg-ebm-ip
  - zap-ves-ip
  - zap-ves-port
  - zap-pw
  - cbos-version-all
  - cbos-version
  - cbos-minor-version
  - docker-image-size


# Rules to execute
rules:

  # Integrated rule to execute everything locally (init-dev)
  release:
    - rule: clean
    - rule: init-dev
    - rule: lint
    - rule: build
    - rule: test
    - rule: image
    - rule: image-dr-check
    - rule: package
    - rule: package-jars
    - rule: install-test

  # Clean workspace
  clean:
    - task: rm
      cmd:
        - rm -rf .bob/
        - rm -rf build/
        - rm -rf k8s-logs/
        - rm -f artifact.properties
        - rm -f helm-install-dry-run.log
        - rm -rf *${fossa-report-name}
    - task: mvn-clean
      docker-image: adp-maven-builder
      docker-flags: &mvn-docker-flags
        - "--env MAVEN_OPTS=${env.MAVEN_OPTS}"
        - "--env HOME=${env.HOME}"
        - "--volume ${env.PROJ_MVN}:/proj/mvn"
        - "--volume ${env.HOME}:${env.HOME}"
      cmd: mvn ${env.MAVEN_CLI_OPTS} clean

  # Common tasks for all init rules
  init-common:
    - task: version
      docker-image: adp-release-auto
      docker-flags:
        - "--env RELEASE"
      cmd: generate-version --is-release ${env.RELEASE} --output version
    - task: rstate
      docker-image: adp-release-auto
      cmd: get_rstate.py ${var.version} > .bob/var.rstate
    - task: commit
      docker-image: adp-release-auto
      cmd:
        - git rev-parse --short HEAD > .bob/var.commithash
        - git rev-parse HEAD > .bob/var.commithash-full
        - git log -1 --format='%aN' > .bob/var.commit-author
        - git log -1 --format='%aE' > .bob/var.commit-email
    - task: fetch-pom-version
      docker-image: adp-maven-builder
      docker-flags: *mvn-docker-flags
      cmd:
        - mvn ${env.MAVEN_CLI_OPTS} help:evaluate -Dexpression=project.version -q -DforceStdout > .bob/var.pom-version
    - task: create-temp-dir
      cmd: mkdir -p ${env.BUILD_DIR}

  # Dev Tasks: only used by manually publishing development/black builds by developers
  init-dev:
    - rule: init-common
    - task: sync-var.version-and-var.pom-version-for-local-dev
      cmd: echo ${var.pom-version} > .bob/var.version
    - task: preliminary-revision # For example: PA1
      cmd: RSTATE=${var.rstate} && echo P${RSTATE:2}1 > .bob/var.revision
    - task: image-repopath-internal
      cmd: echo "${image-dev-repopath}" | cut -f2- -d '/' > .bob/var.image-repopath-internal
    - task: image-registry
      cmd: echo "${image-dev-repopath}" | cut -f1 -d '/' > .bob/var.image-registry
    - task: image-full-name-internal
      cmd: echo "${image-dev-repopath}/${common.docker-image-name}" > .bob/var.image-full-name-internal
    - task: helm-chart-repo-internal
      cmd: echo "${helm-chart-dev-repopath}" > .bob/var.helm-chart-repo-internal
    - task: image-dr-vm-args
      cmd: echo " -DimageDesignRule.config.DR-D470203-041-A=disable -DimageDesignRule.config.DR-D470203-050-A=disable" > .bob/var.image-dr-vm-args

  # CI-Internal Tasks: used by CI to use as temporary storage for testing, only CI user has write access.
  init-precodereview:
    - rule: init-common
    - task: update-pom-version
      cmd:
        - sed -i '0,/${var.pom-version}/s//${var.version}/' pom.xml
    - task: preliminary-revision # For example: PA1
      cmd: RSTATE=${var.rstate} && echo P${RSTATE:2}1 > .bob/var.revision
    - task: image-repopath-internal
      cmd: echo "${image-ci-repopath}" | cut -f2- -d '/' > .bob/var.image-repopath-internal
    - task: image-registry
      cmd: echo "${image-ci-repopath}" | cut -f1 -d '/' > .bob/var.image-registry
    - task: image-full-name-internal
      cmd: echo "${image-ci-repopath}/${common.docker-image-name}" > .bob/var.image-full-name-internal
    - task: helm-chart-repo-internal
      cmd: echo "${helm-chart-ci-repopath}" > .bob/var.helm-chart-repo-internal
    - task: image-dr-vm-args
      cmd: echo " -DimageDesignRule.config.DR-D470203-041-A=disable -DimageDesignRule.config.DR-D470203-050-A=disable" > .bob/var.image-dr-vm-args

  # Drop level tasks: used by CI to publish artifacts after successful CI pipeline execution for a drop build
  init-drop :
    - rule: init-common
    - task: update-pom-version
      cmd:
        - sed -i '0,/${var.pom-version}/s//${var.version}/' pom.xml
    - task: full-revision # For example: A (Note: The Letters I O P Q R W must never be used for Document Revisioning.
      cmd:
        - RSTATE=${var.rstate} && echo ${RSTATE:2} > .bob/var.revision
    - task: image-repopath-internal
      cmd: echo "${image-ci-repopath}" | cut -f2- -d '/' > .bob/var.image-repopath-internal
    - task: image-repopath-drop
      cmd: echo "${image-drop-repopath}" | cut -f2- -d '/' > .bob/var.image-repopath-drop
    - task: image-registry
      cmd: echo "${image-ci-repopath}" | cut -f1 -d '/' > .bob/var.image-registry
    - task: image-full-name-internal
      cmd: echo "${image-ci-repopath}/${common.docker-image-name}" > .bob/var.image-full-name-internal
    - task: helm-chart-repo-internal
      cmd: echo "${helm-chart-ci-repopath}" > .bob/var.helm-chart-repo-internal
    - task: adp-artifacts-properties
      docker-image: adp-release-auto
      cmd: generate-adp-artifacts
        --chart-name ${common.helm-chart-name}
        --chart-version ${var.version}
        --chart-repo ${helm-chart-drop-repo}
        --image-name ${common.docker-image-name}
        --image-version ${var.version}
        --image-repo "${var.image-registry}/${var.image-repopath-drop}"
    - task: write-git-details
      cmd:
        - echo "GIT_TAG=$(git log -1 --pretty=format:'%h')" >> artifact.properties
        - echo "GIT_COMMIT_AUTHOR=$(git log -1 --pretty=format:'%an')" >> artifact.properties
        - echo "GIT_COMMIT_AUTHOR_EMAIL=$(git log -1 --format='%aE')" >> artifact.properties
        - echo "GIT_COMMIT_SUMMARY=$(git log -1 --pretty=format:'%s')" >> artifact.properties
        - echo "GERRIT_CHANGE_URL=${env.GERRIT_CHANGE_URL}" >> artifact.properties
    - task: image-dr-vm-args
      cmd: echo "" > .bob/var.image-dr-vm-args

  lint:
    - task: markdownlint
      docker-image: adp-doc-builder
      cmd: bash -c 'markdownlint --config /etc/markdownlint-cli/adp.yaml $(git ls-files -- \*\.md | cat | xargs)' || true
    - task: vale
      docker-image: adp-doc-builder
      cmd: bash -c 'vale --output line --no-wrap $(git ls-files -- \*\.md | cat | xargs)' || true
    - task: helm
      docker-image: adp-helm-dr-check
      docker-flags:
        - "--env ENABLE_HELM_V3=true"
      cmd: helm3 lint charts/${common.helm-chart-name}
    - task: helm-chart-check
      docker-image: adp-helm-dr-check
      cmd: helm-dr-check --helm-chart charts/${common.helm-chart-name} ${enabled-helm-design-rules} --helm-v3 --output .bob/
    - task: license-check
      docker-image: adp-maven-builder
      docker-flags: *mvn-docker-flags
      cmd: mvn ${env.MAVEN_CLI_OPTS} license:check -DskipTests=true
    - task: metrics-check
      cmd:
        - . ./ci/scripts/metrics-checker.sh --chmod=+x && checkValuesYAML ${common.helm-chart-name}
        - . ./ci/scripts/metrics-checker.sh && checkServiceYAML ${common.helm-chart-name}
        - . ./ci/scripts/metrics-checker.sh && checkDeploymentYAML ${common.helm-chart-name}
        - . ./ci/scripts/metrics-checker.sh && checkHelperTPL ${common.helm-chart-name}
        - . ./ci/scripts/metrics-checker.sh && checkPomXML ${common.helm-chart-name}
        - . ./ci/scripts/metrics-checker.sh && checkCoreApplicationJAVA ${common.helm-chart-name}
        - . ./ci/scripts/metrics-checker.sh && passOrFailCheck

  # Generate documents: .md to .pdf & .html, prepare for uploading to Eridoc later.
  generate-docs:
    - task: markdown-to-pdf
      docker-image: adp-release-auto
      cmd: 'doc-handler generate --config doc/handler-pdf-config.yaml
                                 --output ./build/doc/pdf
                                 --stylesheet doc/stylesheet/pdf_style.css
                                 --format pdf'
    - task: generate-html-docs
      docker-image: adp-release-auto
      cmd: 'doc-handler generate --config doc/handler-html-config.yaml
                                 --output ./build/doc/html
                                 --format html'

  # Upload zip package documents to ARM
  generate-doc-zip-package:
    - task: generate-doc-zip
      docker-image: adp-release-auto
      cmd: 'doc-handler generate --config doc/marketplace_config.yaml
                                 --output ./build/doc-marketplace
                                 --format html
                                 --zip'

  # Upload zip package documents to ARM
  marketplace-upload:
    #Below should be uncommented when doing the SVL document (https://jira-oss.seli.wh.rnd.internal.ericsson.com/browse/IDUN-42629)
    #- task: generate-svl-doc
    #    docker-image: adp-release-auto
    #    cmd: doc-handler generate-svl-replacement   --product-number ${common.image-product-number}
    #        --product-version ${var.version}
    #        --output build/doc-svl-replacement
    #        --format html
    #        --zip
    - task: upload-doc-to-arm-dev
      docker-image: adp-release-auto
      cmd: 'marketplace upload --arm-api-token ${env.SELI_ARTIFACTORY_REPO_PASS}
            --arm-url ${arm-doc-dev}
            --config doc/marketplace_upload_config.yaml
            --dev'
    - task: upload-doc-to-arm-released
      docker-image: adp-release-auto
      cmd: 'marketplace upload --arm-api-token ${env.SELI_ARTIFACTORY_REPO_PASS}
            --arm-url ${arm-doc-released}
            --config doc/marketplace_upload_config.yaml
            --version ${var.version-prefix}'
    - task: refresh-adp-portal-marketplace
      docker-image: adp-release-auto
      cmd: marketplace refresh --portal-token ${env.MARKETPLACE_TOKEN}

  # Build java source code and package jar file, no need image building at this stage
  build:
    - task: mvn-package
      docker-image: adp-maven-builder
      docker-flags: &mvn-docker-flags-with-creds
        - "--env MAVEN_OPTS=${env.MAVEN_OPTS}"
        - "--env HOME=${env.HOME}"
        - "--volume ${env.HOME}:${env.HOME}"
        - "--volume ${env.PROJ_MVN}:/proj/mvn"
        - "--env SELI_ARTIFACTORY_REPO_USER=${env.SELI_ARTIFACTORY_REPO_USER}"
        - "--env SELI_ARTIFACTORY_REPO_PASS=${env.SELI_ARTIFACTORY_REPO_PASS}"
      cmd: mvn ${env.MAVEN_CLI_OPTS} clean install -DskipTests=true

  # Local Modification check
  modification-check:
      - task: check-for-any-local-modification
        cmd:
          - if [ -z "$(git status --porcelain |grep M)" ]; then
            echo -e "\nNO local modifications have been made";
            else
            echo -e "\nThere HAS been local modifications made";
            echo "Modified file(s) are";
            echo "";
            git status --porcelain |grep M;
            echo "------------------------------------------------";
            echo -e "\nRun bob build and commit the changes";
            exit 1;
            fi

  # Run unit tests and jacoco coverage for SonarQube analysis
  test:
    - task: mvn-package
      docker-image: adp-maven-builder
      docker-in-docker: socket
      docker-flags: *mvn-docker-flags-with-creds
      cmd: mvn ${env.MAVEN_CLI_OPTS} clean install jacoco:prepare-agent

  sonar-enterprise-pcr:
    - task: generate-version-prefix
      cmd: cat VERSION_PREFIX > .bob/var.version-prefix
    - task: mvn-sonar-enterprise-sonarqube-analysis
      docker-image: adp-maven-builder
      docker-flags: *mvn-docker-flags-with-creds
      cmd: mvn ${env.MAVEN_CLI_OPTS} sonar:sonar
        -Dsonar.login=${env.SONAR_AUTH_TOKEN}
        -Dsonar.host.url=${env.SONAR_HOST_URL}
        -Dsonar.branch.name=${var.version-prefix}-${env.GERRIT_CHANGE_NUMBER}
        -Dsonar.branch.target=${env.SONAR_BRANCH}
        -Dsonar.exclusions=src/main/java/com/ericsson/oss/adc/models/**

  sonar-enterprise-release:
    - task: sonarqube-analysis
      docker-image: adp-maven-builder
      docker-flags: *mvn-docker-flags-with-creds
      cmd: mvn ${env.MAVEN_CLI_OPTS} sonar:sonar
        -Dsonar.login=${env.SONAR_AUTH_TOKEN}
        -Dsonar.host.url=${env.SONAR_HOST_URL}
        -Dsonar.projectVersion=${var.version}

  cbos-version:
    - task: latest-cbos-version
      docker-image: adp-release-auto
      cmd:
        - curl -u ${env.SELI_ARTIFACTORY_REPO_USER}:${env.SELI_ARTIFACTORY_REPO_PASS} -X POST https://arm.seli.gic.ericsson.se/artifactory/api/search/aql -H "content-type:text/plain" -d 'items.find({ "repo":{"$eq":"proj-ldc-docker-global"}, "path":{"$match":"proj-ldc/common_base_os_release/sles/*"}}).sort({"$desc":["created"]}).limit(2)' 2>/dev/null | grep path | sed -e 's_.*\/\(.*\)".*_\1_'  > .bob/var.cbos-version-all
        - sed -n '/_uploads/!p' .bob/var.cbos-version-all > .bob/var.cbos-version

  # Build a docker image pointing to dirty repository
  image:
    - task: docker-build
      cmd: docker build ${env.PWD}
        --file Dockerfile
        --tag ${var.image-full-name-internal}:${var.version}
        --build-arg CBOS_VERSION=${var.cbos-version}
        --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
        --build-arg COMMIT=${var.commithash}
        --build-arg APP_VERSION=${var.version}
        --build-arg JAR_FILE=eric-oss-sftp-filetrans-${var.version}.jar
        --build-arg RSTATE=${var.rstate}
        --build-arg IMAGE_PRODUCT_NUMBER=${common.image-product-number}
    - task: store-image-size
      cmd : docker images --format "{{.Size}}" ${var.image-full-name-internal}:${var.version} > .bob/var.docker-image-size
    - task: update-characteristic-test-report
      cmd: >
        sed -i "s/\(Image.*: \`\`\`\).*\(\`\`\`\)/\1${var.docker-image-size}\2/" ${characteristic-test-report}
    - task: update-test-report
      cmd: >
        sed -i 's/|\s*Image size\s*|\s*Default (427 MB)\s*|/| Image size | ${var.docker-image-size} |/' ${test-report}

  # Update cbos version in product structure
  update-cbos-version:
    - task: get-cbos-minor-version
      cmd: echo ${common.cbos-image-version} | cut -f1 -d"-" > .bob/var.cbos-minor-version
    - task: update-cbos-minor-version
      cmd: perl -pi -e 's/CBOS_VERSION/${var.cbos-minor-version}/' ${env.PWD}/plms/product_structure.yaml

  # Delete Docker images created
  delete-images:
    - task: delete-internal-image
      cmd: docker image remove ${var.image-full-name-internal}:${var.version} $(docker images -f "dangling=true" -q) || true
    - task: delete-drop-image
      cmd: docker image remove ${image-full-name}:${var.version} $(docker images -f "dangling=true" -q) || true

  # Check for image design rule compliance
  image-dr-check:
    - task: check-image-dr
      docker-image: adp-image-dr-check
      docker-in-docker: socket
      cmd: "image-dr-check
          --image ${var.image-full-name-internal}:${var.version}
          --output .bob/check-image/
          ${var.image-dr-vm-args}"

  # Push image to ci-internal repo and create local version of helm chart
  package-local:
    - task: image-push-internal
      cmd: docker push ${var.image-full-name-internal}:${var.version}
    - task: package-helm-internal
      docker-image: adp-release-auto
      docker-flags:
        - "--env ENABLE_HELM_V3=true"
      cmd: helm-package
        --folder charts/${common.helm-chart-name}
        --workdir .bob --output .bob/${common.helm-chart-name}-internal
        --version ${var.version}
        --replace eric-product-info.yaml:VERSION=${var.version}
        --replace eric-product-info.yaml:REPO_PATH=${var.image-repopath-internal}
        --replace eric-product-info.yaml:IMAGE_NAME=${common.docker-image-name}

  # Push image to ci-internal repo, create internal version of helm chart and pushes it to internal repo
  package:
    - rule: package-local
    - task: helm-upload-internal
      docker-image: adp-release-auto
      docker-flags:
        - "--env ENABLE_HELM_V3=true"
      cmd: upload_file.sh
        --filename=.bob/${common.helm-chart-name}-internal/${common.helm-chart-name}-${var.version}.tgz
        --repository=${var.helm-chart-repo-internal}/${common.helm-chart-name}
        --api-token=${env.SELI_ARTIFACTORY_REPO_PASS}

  package-jars:
    - task: mvn-upload-internal
      docker-image: adp-maven-builder
      docker-flags: *mvn-docker-flags-with-creds
      cmd: mvn ${env.MAVEN_CLI_OPTS} clean deploy -DskipTests=true

  install-test:
    - rule: find-docker-config-basepath
    - rule: helm-dry-run
    - rule: namespace-precheck
    - rule: create-namespace
    - rule: helm-install-prep
    - rule: helm-install
    - rule: healthcheck
    - rule: kaas-info
    - rule: delete-namespace

  find-docker-config-basepath:
    - task: find-docker-config-basepath
      cmd: dirname ${env.DOCKERCONFIG} > .bob/var.docker-config-basepath

  helm-dry-run:
    - rule: find-docker-config-basepath
    - task: helm-dry-run
      docker-image: adp-helm-kubectl
      docker-flags: &docker_flags_kube_config
        - "--env HOME=${env.HOME}"
        - "--env K8S_NAMESPACE=${env.K8S_NAMESPACE}"
        - "--env KUBECONFIG=${env.KUBECONFIG}"
        - "--env ENABLE_HELM_V3"
        - "--env COLLECT_LOGS_SCRIPT_LOCATION"
        - "--volume ${env.PWD}:${env.PWD}"
        - "--volume ${env.HOME}:${env.HOME}"
        - "--volume ${env.KUBECONFIG}:${env.KUBECONFIG}"
        - "--volume ${var.docker-config-basepath}:${var.docker-config-basepath}"
      cmd: helm install .bob/${common.helm-chart-name}-internal/${common.helm-chart-name}-${var.version}.tgz
        --dry-run
        --debug
        --generate-name > helm-install-dry-run.log

  namespace-precheck:
    - rule: find-docker-config-basepath
    - task: find-all-namespaces
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: kubectl get ns ${env.K8S_NAMESPACE} | awk '{if($1=="${env.K8S_NAMESPACE}") print $1};' > .bob/var.save-namespace || true
    - task: delete-namespace
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: kubectl delete namespace ${var.save-namespace} || true

  create-namespace:
    - rule: namespace-precheck
    - rule: find-docker-config-basepath
    - task: create-namespace
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: kubectl create namespace ${env.K8S_NAMESPACE}

  helm-install-prep:
    - rule: find-docker-config-basepath
    - task: helm-install-prep
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: kubectl create secret generic ${image-secret}
        --from-file=.dockerconfigjson=${env.DOCKERCONFIG}
        --type=kubernetes.io/dockerconfigjson
        --namespace ${env.K8S_NAMESPACE} || true

  helm-install:
    - rule: helm-install-prep
    - task: timing:store-start-time-seconds
    - task: helm-install-or-upgrade
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: helm upgrade
        --install ${env.HELM_RELEASE} .bob/${common.helm-chart-name}-internal/${common.helm-chart-name}-${var.version}.tgz
        --namespace ${env.K8S_NAMESPACE}
        --set eric-log-shipper.logshipper.autodiscover.namespace=${env.K8S_NAMESPACE}
        --set imageCredentials.pullSecret=${image-secret}
        --timeout ${env.HELM_INSTALL_TIMEOUT}
        --wait
    - task: timing:store-end-time-seconds
    - task: timing:store-elapsed-time
    - task: update-characteristic-test-report
      cmd: >
        sed -i "s/\(Startup.*: \`\`\`\).*\(\`\`\`\)/\1${var.elapsed-time}\2/" ${characteristic-test-report}
    - task: update-test-report
      cmd: >
        sed -i 's/|\s*Startup time (to fully ready)\s*|\s*Default (3m 14s)\s*|/| Startup time (to fully ready) | ${var.elapsed-time} |/' ${test-report}

  k8s-restart-pod:
    - task: timing:store-start-time-seconds
    - task: restart-pod-and-wait
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      # Have to write the pods to a var because running the get pods command as a subshell command
      # in the delete and wait commands does not work as it complains about not being able to find kubectl.
      # Probably because the subshell command ends up running on the host and not in the container.
      cmd:
        - kubectl get pods --namespace ${env.K8S_NAMESPACE} -o custom-columns=':metadata.name' | grep ${common.helm-chart-name} | awk '{ORS=" "} 1' > .bob/var.service-pods
        - kubectl delete pods --namespace ${env.K8S_NAMESPACE} ${var.service-pods} --wait
        - kubectl get pods --namespace ${env.K8S_NAMESPACE} -o custom-columns=':metadata.name' | grep ${common.helm-chart-name} | awk '{ORS=" "} 1' > .bob/var.service-pods
        - kubectl wait pods --namespace ${env.K8S_NAMESPACE} --for condition=Ready --timeout=${env.HELM_INSTALL_TIMEOUT} ${var.service-pods}
    - task: timing:store-end-time-seconds
    - task: timing:store-elapsed-time
    - task: update-characteristic-test-report
      cmd: >
        sed -i "s/\(Restart.*: \`\`\`\).*\(\`\`\`\)/\1${var.elapsed-time}\2/" ${characteristic-test-report}
    - task: update-test-report
      cmd: >
        sed -i 's/|\s*Restart time (to fully ready)\s*|\s*Default (3m 14s)\s*|/| Restart time (to fully ready) | ${var.elapsed-time} |/' ${test-report}

  characteristics-tests:
    - rule: helm-install
    - rule: k8s-restart-pod

  timing:
    - task: store-start-time-seconds
      cmd: date +"%s" > .bob/var.start-time-seconds
    - task: store-end-time-seconds
      cmd: date +"%s" > .bob/var.end-time-seconds
    - task: store-elapsed-time
      cmd: date -d@$(expr ${var.end-time-seconds} - ${var.start-time-seconds}) -u +%H:%M:%S:%3N > .bob/var.elapsed-time

  helm-install-kgb:
    - rule: helm-install-prep
    - task: prepare-helm-repo
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd:
        - helm repo add ${common.helm-chart-name} ${helm-chart-drop-repo} --username ${env.SELI_ARTIFACTORY_REPO_USER} --password ${env.SELI_ARTIFACTORY_REPO_PASS}
        - helm repo update
    - task: install-kgb-on-kubernetes
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: helm upgrade
        --install ${env.HELM_RELEASE} ${common.helm-chart-name}/${common.helm-chart-name}
        --namespace ${env.K8S_NAMESPACE}
        --set eric-log-shipper.logshipper.autodiscover.namespace=${env.K8S_NAMESPACE}
        --set imageCredentials.pullSecret=${image-secret}
        --timeout ${env.HELM_INSTALL_TIMEOUT}
        --wait
        --devel
    - rule: healthcheck

  helm-upgrade:
    - rule: helm-install-kgb
    - rule: helm-install

  healthcheck:
    - rule: find-docker-config-basepath
    - task: healthcheck
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: ./healthcheck.sh

  kaas-info:
    - task: get-kaas-info
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd:
        - kubectl get nodes -o=jsonpath='{.items[0].metadata.labels.kaas/version}' > .bob/var.kaas-version
        - kubectl config current-context > .bob/var.kaas-current-context
    - task: output-kaas-info
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd:
        - echo -e '# KaaS Version:' >> ${env.KAAS_INFO_FILE} >> ${env.KAAS_INFO_FILE}
        - kubectl get nodes -o=jsonpath='{.items[0].metadata.labels.kaas/version}' >> ${env.KAAS_INFO_FILE}
        - echo -e '\n\n# CCD Version:' >> ${env.KAAS_INFO_FILE} >> ${env.KAAS_INFO_FILE}
        - kubectl get nodes -o=jsonpath='{.items[0].metadata.labels.erikube/version}' >> ${env.KAAS_INFO_FILE}
        - echo -e '\n\n# KaaS Release Information:' >> ${env.KAAS_INFO_FILE}
        - echo -e "Ericsson Web Services - https://ews.rnd.gic.ericsson.se/cd.php?cluster=${var.kaas-current-context}" >> ${env.KAAS_INFO_FILE}
        - echo -e "KaaS release information - https://confluence.lmera.ericsson.se/display/AD/${var.kaas-version}" >> ${env.KAAS_INFO_FILE}
        - echo -e '\n# Kubectl Version:' >> ${env.KAAS_INFO_FILE}
        - kubectl version >> ${env.KAAS_INFO_FILE}
        - echo -e '\n# Kubectl Cluster Info:' >> ${env.KAAS_INFO_FILE} >> ${env.KAAS_INFO_FILE}
        - kubectl cluster-info | sed 's/\x1B\[[0-9;]\{1,\}[A-Za-z]//g' >> ${env.KAAS_INFO_FILE}
        - echo -e '\n# Kubectl Config Context:' >> ${env.KAAS_INFO_FILE} >> ${env.KAAS_INFO_FILE}
        - kubectl config get-contexts >> ${env.KAAS_INFO_FILE}
        - echo -e '\n# Helm Version:' >> ${env.KAAS_INFO_FILE}
        - helm version >> ${env.KAAS_INFO_FILE}

  delete-namespace:
    - rule: find-docker-config-basepath
    - task: delete-release
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: helm delete ${env.HELM_RELEASE} --namespace ${env.K8S_NAMESPACE} || true
    - task: delete-namespace
      docker-image: adp-helm-kubectl
      docker-flags: *docker_flags_kube_config
      cmd: kubectl delete namespace ${env.K8S_NAMESPACE}

  # Publish docker images and helm charts to drop repository
  # Call publish only when merged to master
  publish:
    - task: package-helm-public
      docker-image: adp-release-auto
      docker-flags:
        - "--env ENABLE_HELM_V3=true"
      cmd: helm-package
        --folder charts/${common.helm-chart-name}
        --workdir .bob --output build
        --version ${var.version}
        --replace VERSION=${var.version}
        --replace eric-product-info.yaml:VERSION=${var.version}
        --replace eric-product-info.yaml:REPO_PATH=${var.image-repopath-drop}
        --replace eric-product-info.yaml:IMAGE_NAME=${common.docker-image-name}
    - task: helm-upload-to-release-repo
      docker-image: adp-release-auto
      docker-flags:
        - "--env ENABLE_HELM_V3=true"
      cmd: upload_file.sh
        --filename=build/${common.helm-chart-name}-${var.version}.tgz
        --repository=${helm-chart-release-repo}/${common.helm-chart-name}
        --api-token=${env.SELI_ARTIFACTORY_REPO_PASS}
    - task: image-pull-internal
      cmd: docker pull ${var.image-full-name-internal}:${var.version}
    - task: image-tag-public
      cmd: docker tag ${var.image-full-name-internal}:${var.version} ${image-full-name}:${var.version}
    - task: image-push-public
      cmd: docker push ${image-full-name}:${var.version}
    - task: helm-upload
      docker-image: adp-release-auto
      docker-flags:
        - "--env ENABLE_HELM_V3=true"
      cmd: upload_file.sh
        --filename=build/${common.helm-chart-name}-${var.version}.tgz
        --repository=${helm-chart-drop-repo}/${common.helm-chart-name}
        --api-token=${env.SELI_ARTIFACTORY_REPO_PASS}
    - rule: publish-jars

  publish-jars:
    - task: mvn-upload
      docker-image: adp-maven-builder
      docker-flags:
        - ${env.DOCKER_VOLUME_MAPPING_PASSWD}
        - "--volume ${env.HOME}:${env.HOME}"
        - "--volume ${env.PROJ_MVN}:/proj/mvn"
        - "--env SELI_ARTIFACTORY_REPO_USER=${env.SELI_ARTIFACTORY_REPO_USER}"
        - "--env SELI_ARTIFACTORY_REPO_PASS=${env.SELI_ARTIFACTORY_REPO_PASS}"
        - "--env MAVEN_OPTS"
      cmd:
        - git stash && git checkout master
        - mvn ${env.MAVEN_CLI_OPTS} -Dmaven.javadoc.skip=true -DskipTests=true clean deploy

  helm-chart-check-report-warnings:
    - task: helm-chart-check-report-warnings
      cmd:
        - if grep -q ">WARNING<" .bob/design-rule-check-report.xml; then
            echo true > .bob/var.helm-chart-check-report-warnings;
          else
            echo false > .bob/var.helm-chart-check-report-warnings;
          fi

  collect-k8s-logs:
    - task: collect-logs-using-script
      docker-image: adp-helm-kubectl
      docker-flags:
        - "--env ENABLE_HELM_V3"
        - "--env HOME=${env.HOME}"
        - "--env K8S_NAMESPACE=${env.K8S_NAMESPACE}"
        - "--env KUBECONFIG=${env.KUBECONFIG}"
        - "--env SERO_ARTIFACTORY_REPO_USER=${env.SERO_ARTIFACTORY_REPO_USER}"
        - "--env SERO_ARTIFACTORY_REPO_PASS=${env.SERO_ARTIFACTORY_REPO_PASS}"
        - "--env COLLECT_LOGS_SCRIPT_LOCATION"
        - "--env COLLECT_LOGS_SCRIPT_FILE_NAME"
        - "--env COLLECT_LOGS_SINCE_RELATIVE_TIME"
        - "--env COLLECT_LOGS_DIR"
        - "--env HOME=${env.HOME}"
        - "--volume ${env.HOME}:${env.HOME}"
        - "--volume ${env.KUBECONFIG}:${env.KUBECONFIG}"
      cmd:
        - mkdir -p ${env.COLLECT_LOGS_DIR}
        - kubectl config view > ${env.COLLECT_LOGS_DIR}/kubectl.config
        - kubectl get ns > ${env.COLLECT_LOGS_DIR}/kubectl-get-ns.log
        - helm ls -Aa > ${env.COLLECT_LOGS_DIR}/helm-ls-Aa.log
        - printenv | grep -v CREDENTIALS | grep -v ARTIFACTORY > ${env.COLLECT_LOGS_DIR}/printenv.log
        - curl -u ${env.SERO_ARTIFACTORY_REPO_USER}:${env.SERO_ARTIFACTORY_REPO_PASS} ${env.COLLECT_LOGS_SCRIPT_LOCATION}/${env.COLLECT_LOGS_SCRIPT_FILE_NAME} > ${env.COLLECT_LOGS_DIR}/${env.COLLECT_LOGS_SCRIPT_FILE_NAME}
        - chmod 777 ${env.COLLECT_LOGS_DIR}/${env.COLLECT_LOGS_SCRIPT_FILE_NAME}
        - sh -c "cd ${env.COLLECT_LOGS_DIR} && ./${env.COLLECT_LOGS_SCRIPT_FILE_NAME} ${env.K8S_NAMESPACE} ${env.COLLECT_LOGS_SINCE_RELATIVE_TIME}"

  # fossa analyze stage
  fossa-analyze:
    - task: fossa-analyze
      docker-image: adp-maven-builder
      docker-flags:
        - ${docker-params}
        - "--env FOSSA_API_KEY=${env.FOSSA_API_KEY}"
        - "--env MAVEN_OPTS=${env.MAVEN_OPTS}"
        - "--env HOME=${env.HOME}"
        - "--volume ${env.PROJ_MVN}:/proj/mvn"
        - "--volume ${env.HOME}:${env.HOME}"
      cmd:
        fossa analyze --revision ${var.version} --team ${fossa-team-name} --endpoint ${fossa-server-endpoint} --project ${fossa-project-name}

  # fossa scan status stage
  fossa-scan-status-check:
    - task: fossa-scan-status-check
      docker-image: adp-release-auto
      docker-flags:
        - "--env FOSSA_API_KEY=${env.FOSSA_API_KEY}"
      cmd: fossa_scan_status_check -s ${fossa-server-endpoint} -f custom -p ${fossa-project-name} -r ${var.version} -t ${env.FOSSA_API_KEY} -dl 15

  # New attribution format
  fetch-fossa-report-attribution:
    - task: fetch-fossa-report-attribution
      docker-image: adp-maven-builder
      docker-flags:
        - "--env FOSSA_API_KEY=${env.FOSSA_API_KEY}"
      cmd: fossa report attribution
        --endpoint ${fossa-server-endpoint}
        --project ${fossa-project-name}
        --revision ${var.version} --json > ${fossa-report-name}

  # This script will check in Bazaar for 3PP that are registered and listed in ${dependency-file-name}
  dependency-update:
    - task: dependency-update
      docker-image: adp-release-auto
      cmd: dependencies update
        --fossa-report ${fossa-report-name}
        --dependencies ${dependency-file-name}

  scan-scas:
    - task: update-scan-scas
      description: Converts the FOSSA Report into a YAML file. A scan in Scas is performed to fill details about each dependency.
      docker-image: adp-release-auto
      cmd: dependencies update
        --fossa-report ${fossa-report-name}
        --dependencies ${dependency-file-name}
        --scan-scas
        --scas-refresh-token ${env.SCAS_TOKEN}
        --link-dependencies
        --sort || true
        --transform-components

  # Lint the helm chart and run the helm design rules checker
  dependency-validate:
    - task: dependency-validate
      docker-image: adp-release-auto
      cmd: dependencies validate
           --dependencies ${dependency-file-name}
           --allow-esw4

  # fossa related artifact (fossa.report.json and dependancy.yaml)
  fossa-scan-artifact-upload:
    - task: fossa-scan-artifact-upload
      docker-image: adp-release-auto
      cmd:
        bash -c 'tar czf ${fossa-scan-artifact-file-name} ${dependency-file-name} ${fossa-report-name};
        curl -u '${env.SELI_ARTIFACTORY_REPO_USER}:${env.SELI_ARTIFACTORY_REPO_PASS}' -X PUT -T ${fossa-scan-artifact-file-name} ${fossa-scan-report-artifact-path}/${fossa-scan-artifact-file-name}'

  hadolint-scan:
    - task: hadolint-scan-test
      docker-image: hadolint-scan
      docker-flags:
        - "--workdir /app/"
        - "-v ${env.PWD}/config/hadolint_config.yaml:/config/hadolint_config.yaml"
        - "-v ${env.PWD}/Dockerfile:/Dockerfile"
        - "-v ${env.PWD}/build/va-reports/hadolint-scan:/tmp/reports/"
      cmd: "-p ${common.helm-chart-name} -f /Dockerfile -c /config/hadolint_config.yaml; echo $? > .bob/var.resultcode_hadolint_check"

  evaluate-design-rule-check-resultcodes:
    - task: hadolint-result-check
      cmd: sh -c '
        if [ ${var.resultcode_hadolint_check} -ne 0 ]; then
        echo "Failure in hadolint checker";
        exit ${var.resultcode_hadolint_check};
        fi ;'

  kubehunter-scan:
    - task: get-config
      cmd: cp -v .kube/config  ${env.PWD}/config/config
    - task: kubehunter-scan-test
      docker-image: va-scan-kubehunter
      docker-flags:
        - "--workdir /opt/kubehunter/"
        - ${env.DOCKER_VOLUME_MAPPING_PASSWD}
        - "--env KUBECONFIG=${env.KUBECONFIG}"
        - "--volume ${env.KUBECONFIG}:${env.KUBECONFIG}:ro"
        - "-v ${env.PWD}/config:/opt/kubehunter/conf"
        - "-v ${env.PWD}/build/va-reports/kubehunter-report/:/tmp/reports"
      cmd: " "

  # Run kubeaudit
  kube-audit:
    - task: helm-template
      docker-image: adp-release-auto
      cmd: "helm template charts/${common.helm-chart-name} --output-dir=.bob/helm_src"
    - task: kube-audit-test
      docker-image: va-scan-kubeaudit
      docker-flags:
        - "--workdir /opt/va-scan-kubeaudit/"
        - "-v ${env.PWD}/config:/opt/va-scan-kubeaudit/conf"
        - "-v ${env.PWD}/build/va-reports/kube-audit-report/:/tmp/reports"
        - "-v ${env.PWD}/.bob/helm_src:/tmp/src"
      cmd: " "

  # Run kubesec scanning
  kubesec-scan:
    - task: helm-template
      docker-image: va-scan-kubesec
      cmd: "helm template charts/${common.helm-chart-name} --output-dir=.bob/helm_kubesec"
    - task: remove-files-not-for-scanning
      cmd:
        - rm -rf .bob/helm_kubesec/${common.helm-chart-name}/templates/tests
        - rm -rf .bob/helm_kubesec/${common.helm-chart-name}/templates/hpa.yaml
        - rm -rf .bob/helm_kubesec/${common.helm-chart-name}/templates/rolebinding.yaml
    - task: kubesec-scan-test
      docker-image: va-scan-kubesec
      docker-flags:
        - "--workdir /opt/va-scan-kubesec/"
        - "-v ${env.PWD}/config:/opt/va-scan-kubesec/conf"
        - "-v ${env.PWD}/build/va-reports/kubesec-reports/:/tmp/reports"
        - "-v ${env.PWD}/.bob/helm_kubesec/:/tmp/src"
      cmd: " "

  fetch-xray-report:
    - task: fetch-xray-report
      docker-image: adp-release-auto
      cmd: bash -c 'fetch-xray
        --config ${env.PWD}/config/xray_report.config
        --debug
        --user ${env.XRAY_USER}
        --apikey ${env.XRAY_APIKEY}
        --output ${env.PWD}/build/va-reports/xray-reports/xray_report.json
        --set artifactory-subpath=${project-subpath}
        --set image=${common.docker-image-name}
        --set version=${var.version}
        --raw-output ${env.PWD}/build/va-reports/xray-reports/raw_xray_report.json'

  trivy-inline-scan:
    - task: fetch-image
      cmd:
        - "docker pull ${image-to-scan}"
        - mkdir -p build/va-reports/trivy-reports
    - task: trivy-inline-scan-console-report
      docker-image: trivy-inline-scan
      docker-in-docker: socket
      cmd: --offline-scan --timeout 30m --skip-java-db-update ${image-to-scan} 2>&1 | tee build/va-reports/trivy-reports/trivy.console.summary.txt  # workaround suggested in https://jira-oss.seli.wh.rnd.internal.ericsson.com/browse/IDUN-55557
    - task: trivy-inline-scan-json-report
      docker-image: trivy-inline-scan
      docker-in-docker: socket
      cmd: --format json --output build/va-reports/trivy-reports/trivy.report.json --offline-scan --timeout 30m --skip-java-db-update ${image-to-scan} # workaround suggested in https://jira-oss.seli.wh.rnd.internal.ericsson.com/browse/IDUN-55557

  anchore-grype-scan:
    - task: fetch-image
      cmd: "docker pull ${image-to-scan}"
    - task: anchore-grype-scan
      docker-image: grype-scan
      docker-in-docker: socket
      cmd: grype_scan
            --image ${image-to-scan}
            --report-dir build/va-reports/anchore-reports
            --db-url https://toolbox-data.anchore.io/grype/databases/listing.json

  cleanup-anchore-trivy-images:
    - task: clean-images
      cmd:
        - "docker image rm -f ${anchore-grype-image}"
        - "docker image rm -f ${trivy-image}"
        - "docker image rm -f ${image-to-scan}"

  # Fetch vulnerabililty report VA 2.0
  generate-VA-report-V2:
    - task: no-upload
      docker-image: adp-release-auto
      docker-flags:
        - --env VHUB_API_TOKEN
      cmd: bash -c 'va-report
           --set version=${var.version}
           --config ${env.PWD}/config/va-report.config
           --output ${env.PWD}/build/va-reports/Vulnerability_Report_2.0.md
           --md
           --debug
           --anchore-reports ${env.PWD}/build/va-reports/anchore-reports
           --trivy-reports ${env.PWD}/build/va-reports/trivy-reports
           --xray-report ${env.PWD}/build/va-reports/xray-reports/xray_report.json
           --raw-xray-report ${env.PWD}/build/va-reports/xray-reports/raw_xray_report.json
           --kubeaudit-reports ${env.PWD}/build/va-reports/kube-audit-report/${common.helm-chart-name}/templates/deployment
           --kubesec-reports ${env.PWD}/build/va-reports/kubesec-reports'; exit 0;
    - task: upload
      docker-image: adp-release-auto
      docker-flags:
        - --env VHUB_API_TOKEN
      cmd: bash -c 'va-report
           --set version=${var.version}
           --config ${env.PWD}/config/va-report.config
           --output ${env.PWD}/build/va-reports/Vulnerability_Report_2.0.md
           --md
           --debug
           --anchore-reports ${env.PWD}/build/va-reports/anchore-reports
           --trivy-reports ${env.PWD}/build/va-reports/trivy-reports
           --xray-report ${env.PWD}/build/va-reports/xray-reports/xray_report.json
           --raw-xray-report ${env.PWD}/build/va-reports/xray-reports/raw_xray_report.json
           --kubeaudit-reports ${env.PWD}/build/va-reports/kube-audit-report/${common.helm-chart-name}/templates/deployment
           --kubesec-reports ${env.PWD}/build/va-reports/kubesec-reports
           --upload-scan-results'; exit 0;

  zap-scan:
    - task: zap-scan
      docker-image: adp-helm-kubectl
      docker-flags:
        - "--env KUBECONFIG=${env.KUBECONFIG}"
        - "--volume ${env.KUBECONFIG}:${env.KUBECONFIG}:ro"
        - "--volume ${env.PWD}:${env.PWD}"
      cmd: test.py --helm-v3
          --kubernetes-admin-conf=${env.KUBECONFIG}
          --helm-user=${env.SERO_ARTIFACTORY_REPO_USER}
          --arm-api-token=${env.SERO_ARTIFACTORY_REPO_PASS}
          --kubernetes-namespace=${env.K8S_NAMESPACE}
          --chart-archive=.bob/${common.helm-chart-name}-internal/${common.helm-chart-name}-${var.version}.tgz
          --skip-upgrade-test
          --only-zap-test
          --zap-config=${zap-config} ; exit 0
    - task: zap-tar
      cmd: tar -czf
        ${env.PWD}/build/va-reports/${common.helm-chart-name}_${var.version}_owasp_zap_report.tgz
        ${env.PWD}/build/va-reports/zap_report/*.json

  # Create and push git tag. Example v1.0.0-55
  create-git-tag:
    - task: git-tag
      docker-image: adp-release-auto
      docker-flags:
        - --env GERRIT_USERNAME
        - --env GERRIT_PASSWORD
      cmd: version-handler create-git-tag
           --git-repo-url ${git-repo-url}
           --tag ${var.version}
           --message "Release ${var.version}"
